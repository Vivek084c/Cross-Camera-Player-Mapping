{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d25e13c",
   "metadata": {},
   "source": [
    "### exploring pose estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a068f7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of video.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "\n",
    "# --- CONFIG ---\n",
    "video_path = \"dataset/tacticam.mp4\"  # or \"dataset/broadcast.mp4\"\n",
    "output_dir = \"output_pose_overlay\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "max_frames = 5\n",
    "\n",
    "yolo_model = YOLO(\"models/best.pt\")\n",
    "pose_model = YOLO(\"yolov8n-pose.pt\")  # Download from Ultralytics if needed\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "frame_count = 0\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "while frame_count < max_frames:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"End of video.\")\n",
    "        break\n",
    "\n",
    "    # --- Detect players ---\n",
    "    det_result = yolo_model.predict(source=frame, conf=0.75, save=False, verbose=False)[0]\n",
    "    annotated = frame.copy()\n",
    "\n",
    "    # Create frame directory\n",
    "    frame_dir = os.path.join(output_dir, f\"frame_{frame_count}\")\n",
    "    os.makedirs(frame_dir, exist_ok=True)\n",
    "\n",
    "    if det_result.boxes is not None:\n",
    "        for i, box in enumerate(det_result.boxes):\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "            cls_id = int(box.cls[0].item())\n",
    "            class_name = yolo_model.names[cls_id]\n",
    "            if class_name.lower() != \"player\":\n",
    "                continue\n",
    "\n",
    "            # --- Crop player and run pose estimation on crop ---\n",
    "            crop = frame[y1:y2, x1:x2]\n",
    "            pose_result = pose_model.predict(source=crop, conf=0.3, save=False, verbose=False)[0]\n",
    "\n",
    "            # Overlay pose keypoints on the crop\n",
    "            crop_pose = crop.copy()\n",
    "            if pose_result.keypoints is not None and len(pose_result.keypoints) > 0:\n",
    "                for kp in pose_result.keypoints.xy:\n",
    "                    for (px, py) in kp:\n",
    "                        cv2.circle(crop_pose, (int(px), int(py)), 3, (0, 255, 255), -1)\n",
    "\n",
    "            # Save player crop with pose overlay\n",
    "            crop_pose_path = os.path.join(frame_dir, f\"player_{i}_pose.jpg\")\n",
    "            cv2.imwrite(crop_pose_path, crop_pose)\n",
    "\n",
    "            # Paste the crop with pose overlay back to the annotated frame\n",
    "            annotated[y1:y2, x1:x2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc37013",
   "metadata": {},
   "source": [
    "## using OpenPifPaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d52b28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1bea99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
